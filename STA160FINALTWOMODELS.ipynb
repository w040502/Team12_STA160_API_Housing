{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d866a18-6576-4075-916f-e71173746e93",
   "metadata": {},
   "source": [
    "Importing all the packages needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ed08fdd-831a-4aa4-b8ed-435d95a03c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.base import clone"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e99e26-237a-489e-8db9-974302c1dec6",
   "metadata": {},
   "source": [
    "# Housing Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef17689-595e-4764-8433-642a0778d02f",
   "metadata": {},
   "source": [
    "Reading in the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "002dbfc1-c415-4b7f-83b4-d1a0ae81a49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "housingdata = pd.read_csv(\"/Users/rox/Desktop/Team12_STA160_Website/housingvars.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a7cc56-1ece-4fb5-8556-986399707b97",
   "metadata": {},
   "source": [
    "splitting the data into training/test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "44b9529c-a20d-4b0a-bdb7-0803e6aa89b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "County          Train Rows   Test Rows   \n",
      "----------------------------------------\n",
      "Los Angeles     1260         315         \n",
      "Fresno          816          205         \n",
      "San Diego       807          202         \n",
      "Sacramento      799          200         \n",
      "San Francisco   679          170         \n",
      "Santa Clara     637          160         \n",
      "Alameda         546          137         \n"
     ]
    }
   ],
   "source": [
    "counties = [\"Los Angeles\", \"Fresno\", \"San Diego\", \"Sacramento\", \"San Francisco\", \"Santa Clara\", \"Alameda\"]\n",
    "housingdata = housingdata[housingdata[\"County\"].isin(counties)].copy()\n",
    "housingdata = housingdata.drop(columns=['City', 'State'], errors='ignore')\n",
    "\n",
    "for county in counties:\n",
    "    county_data = housingdata[housingdata['County'] == county]\n",
    "\n",
    "    # Split 80% train, 20% test\n",
    "    X_train, X_test = train_test_split(\n",
    "        county_data,\n",
    "        test_size=0.2,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    # Save to globals with county-specific names\n",
    "    train_var_name = f\"{county.replace(' ', '_')}_train\"\n",
    "    test_var_name  = f\"{county.replace(' ', '_')}_test\"\n",
    "\n",
    "    globals()[train_var_name] = X_train.reset_index(drop=True)\n",
    "    globals()[test_var_name]  = X_test.reset_index(drop=True)\n",
    "\n",
    "# --------------------------\n",
    "# Step 3: Print row counts per county\n",
    "# --------------------------\n",
    "print(f\"{'County':<15} {'Train Rows':<12} {'Test Rows':<12}\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "for county in counties:\n",
    "    train_rows = globals()[f\"{county.replace(' ', '_')}_train\"].shape[0]\n",
    "    test_rows  = globals()[f\"{county.replace(' ', '_')}_test\"].shape[0]\n",
    "    print(f\"{county:<15} {train_rows:<12} {test_rows:<12}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42936e71-9732-4fed-aaab-b53cbaa0da61",
   "metadata": {},
   "source": [
    "cleaning the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d02c7638-0a2a-4211-b2c7-8654bec93655",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "County          Train Rows   Test Rows   \n",
      "----------------------------------------\n",
      "Los Angeles     1111         291         \n",
      "Fresno          710          177         \n",
      "San Diego       675          167         \n",
      "Sacramento      676          167         \n",
      "San Francisco   679          170         \n",
      "Santa Clara     632          157         \n",
      "Alameda         545          136         \n"
     ]
    }
   ],
   "source": [
    "#dropping problematic SF columns, cleaning all other columns too\n",
    "sf_train = globals()['San_Francisco_train'].drop(columns=['Population'])\n",
    "sf_test  = globals()['San_Francisco_test'].drop(columns=['Population'])\n",
    "\n",
    "# Fill NAs only in numeric columns\n",
    "numeric_cols_train = sf_train.select_dtypes(include='number').columns\n",
    "numeric_cols_test  = sf_test.select_dtypes(include='number').columns\n",
    "\n",
    "sf_train[numeric_cols_train] = sf_train[numeric_cols_train].fillna(0)\n",
    "sf_test[numeric_cols_test]   = sf_test[numeric_cols_test].fillna(0)\n",
    "\n",
    "# Update global variables\n",
    "globals()['San_Francisco_train'] = sf_train\n",
    "globals()['San_Francisco_test']  = sf_test\n",
    "\n",
    "# --------------------------\n",
    "# Handle other counties\n",
    "# --------------------------\n",
    "other_counties = [\"Los_Angeles\", \"Fresno\", \"San_Diego\", \"Sacramento\", \"Santa_Clara\", \"Alameda\"]\n",
    "\n",
    "for county in other_counties:\n",
    "    globals()[f\"{county}_train\"] = globals()[f\"{county}_train\"].dropna()\n",
    "    globals()[f\"{county}_test\"]  = globals()[f\"{county}_test\"].dropna()\n",
    "\n",
    "print(f\"{'County':<15} {'Train Rows':<12} {'Test Rows':<12}\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "for county in counties:\n",
    "    train_rows = globals()[f\"{county.replace(' ', '_')}_train\"].shape[0]\n",
    "    test_rows  = globals()[f\"{county.replace(' ', '_')}_test\"].shape[0]\n",
    "    print(f\"{county:<15} {train_rows:<12} {test_rows:<12}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "059a7e70-bfb5-4d0b-a0ab-5accf6e72ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_county_models(model, counties, globals_dict, \n",
    "                           feature_func=None, log_target=False, winsor_q=0.99):\n",
    "    county_models = {}\n",
    "    county_metrics = {}\n",
    "\n",
    "    print(f\"{'County':<15} {'RMSE':<12} {'R2':<10} {'Extra':<10}\")\n",
    "    print(\"-\"*55)\n",
    "\n",
    "    for county in counties:\n",
    "        county_key = county.replace(\" \", \"_\")\n",
    "        train_df = globals_dict[f\"{county_key}_train\"].copy()\n",
    "        test_df  = globals_dict[f\"{county_key}_test\"].copy()\n",
    "\n",
    "        X_train = train_df.drop(columns=['Price', 'County'], errors='ignore')\\\n",
    "                          .select_dtypes(include=['float64','int64'])\n",
    "        X_test = test_df[X_train.columns]\n",
    "\n",
    "        # Apply optional feature engineering\n",
    "        if feature_func:\n",
    "            X_train = feature_func(X_train)\n",
    "            X_test  = feature_func(X_test)\n",
    "\n",
    "        y_train = train_df['Price'].values\n",
    "        y_test  = test_df['Price'].values\n",
    "\n",
    "        # Apply winsorization + log transform if needed\n",
    "        if log_target:\n",
    "            y_train = np.log1p(np.clip(y_train, None, np.quantile(y_train, winsor_q)))\n",
    "            y_test  = np.log1p(np.clip(y_test,  None, np.quantile(y_test,  winsor_q)))\n",
    "\n",
    "        # Clone and fit model\n",
    "        county_model = clone(model)\n",
    "        county_model.fit(X_train, y_train)\n",
    "        y_pred = county_model.predict(X_test)\n",
    "\n",
    "        # If log target, inverse transform\n",
    "        if log_target:\n",
    "            y_pred = np.expm1(y_pred)\n",
    "            y_test = np.expm1(y_test)\n",
    "\n",
    "        rmse = root_mean_squared_error(y_test, y_pred)\n",
    "        r2   = r2_score(y_test, y_pred)\n",
    "\n",
    "        # Extra info for RF\n",
    "        extra_info = \"\"\n",
    "        if isinstance(county_model, RandomForestRegressor):\n",
    "            oob_r2 = getattr(county_model, 'oob_score_', None)\n",
    "            extra_info = f\"OOB={oob_r2:.4f}\" if oob_r2 else \"N/A\"\n",
    "            # Top 5 features\n",
    "            if hasattr(county_model, 'feature_importances_'):\n",
    "                fi = pd.Series(county_model.feature_importances_, index=X_train.columns)\\\n",
    "                        .sort_values(ascending=False)\n",
    "                top5 = \", \".join(fi.head(5).index.tolist())\n",
    "                extra_info += f\" | top: {top5}\"\n",
    "\n",
    "        county_models[county] = county_model\n",
    "        county_metrics[county] = {'RMSE': rmse, 'R2': r2, 'Extra': extra_info}\n",
    "\n",
    "        print(f\"{county:<15} {rmse:<12.2f} {r2:<10.4f} {extra_info:<10}\")\n",
    "\n",
    "    return county_models, county_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6458799-5530-4c79-871e-ba73570894ae",
   "metadata": {},
   "source": [
    "**Best performing Random Forests model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d614fcee-b68a-4f76-abdd-a5f69d39eeff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "County          RMSE         R2         Extra     \n",
      "-------------------------------------------------------\n",
      "Los Angeles     504704.68    0.8613     OOB=0.8044 | top: Living Space, Longitude, Latitude, City Average Household Income, Beds\n",
      "Fresno          117050.50    0.6061     OOB=0.6351 | top: Living Space, Latitude, Beds, Longitude, Baths\n",
      "San Diego       470626.17    0.7593     OOB=0.8181 | top: Living Space, Longitude, Latitude, Beds, Baths\n",
      "Sacramento      149599.82    0.6830     OOB=0.5807 | top: Living Space, Latitude, Longitude, Beds, Baths\n",
      "San Francisco   618900.33    0.7057     OOB=0.7126 | top: Living Space, Latitude, Baths, Longitude, Beds\n",
      "Santa Clara     357813.97    0.6728     OOB=0.6512 | top: Living Space, Longitude, Latitude, Beds, Baths\n",
      "Alameda         238611.22    0.6799     OOB=0.7594 | top: Living Space, Latitude, Longitude, Beds, Baths\n"
     ]
    }
   ],
   "source": [
    "rf_model = RandomForestRegressor(n_estimators=200, oob_score=True, random_state=42)\n",
    "\n",
    "county_rf_models, county_rf_metrics = evaluate_county_models(\n",
    "    rf_model,\n",
    "    counties,\n",
    "    globals(),\n",
    "    feature_func=None,\n",
    "    log_target=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc2d963-30d7-47b5-bad9-d7220450240e",
   "metadata": {},
   "source": [
    "The XGBoost and Random Forests models perform similarly for the Housing data, but since RF has more accurate predictions for expensive markets such as Los Angeles and San Francisco, we will stick with the Random Forests model as our final model to use."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pythonProject5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
